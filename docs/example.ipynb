{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial on Analyzing Group Chats\n",
    "\n",
    "Reading all the messages from a group chat can be a tedious task, especially when you receive over 100 text messages while you are away. `messageanalyzer` can alleviate your heavy reading load by providing an accessible gateway to Natural Language Processing (NLP) and supporting you with fast, efficient analyzing tools. This is a short tutorial on performing several Natural Language Processing (NLP) tasks on group chats using `messageanalyzer`. \n",
    "\n",
    "For this tutorial, we will introduce and guide you through four popular NLP tasks leveraging the functions in `messageanalyzer`:\n",
    "- Extract keywords\n",
    "- Extract topics\n",
    "- Sentiment analysis\n",
    "- Detect language patterns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import\n",
    "\n",
    "First, let's import `messageanalyzer` as below. We can check the version of `messageanalyzer` by using the attribute `.__version__`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2\n"
     ]
    }
   ],
   "source": [
    "import messageanalyzer\n",
    "\n",
    "print(messageanalyzer.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a list of sample texts that cover a diverse range of conversations among peers. We will work on this sample texts for the majority of the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = [\n",
    "    \"Hey, has anyone watched the latest episode of that new series?\",\n",
    "    \"Not yet! Is it worth watching?\",\n",
    "    \"Totally! The twists this season are insane.\",\n",
    "    \"Okay, now I’m intrigued. Adding it to my watchlist.\",\n",
    "    \"I’m thinking of baking cookies today. Any flavor suggestions?\",\n",
    "    \"Chocolate chip, always a classic!\",\n",
    "    \"Good choice! I’ll try adding some sea salt on top for extra flavor.\",\n",
    "    \"Ooh, sea salt on cookies? That sounds amazing. Let us know how it turns out.\"\n",
    "    \"What’s the best vacation spot you’ve been to?\",\n",
    "    \"Bali, hands down. The beaches are incredible.\",\n",
    "    \"Oh, I’ve always wanted to visit Bali. Did you go to any of the waterfalls there?\",\n",
    "    \"Yes! Tegenungan Waterfall was breathtaking.\",\n",
    "    \"Does anyone else feel like AI is moving so fast?\",\n",
    "    \"For sure. It’s exciting but also a little scary sometimes.\",\n",
    "    \"Agreed. I mean, just look at how tools like ChatGPT are changing how we work.\",\n",
    "    \"True, but it’s also helping with so many tasks I used to find tedious.\",\n",
    "    \"I just got a new gaming headset, and it’s a game-changer!\",\n",
    "    \"Nice! Which one did you get?\",\n",
    "    \"The HyperX Cloud II. The sound quality is amazing, and it’s super comfortable.\",\n",
    "    \"I’ve heard good things about that one. Great pick!\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword Extraction\n",
    "\n",
    "Keyword extraction is a technique to identify and extract the most relevant words or phrases from a given set of text messages. This function supports keyword extraction by using the Term Frequency-Inverse Document Frequency (TF-IDF). It is helpful in summarizing text, identifying key terms, or preprocessing data for further text analysis tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the keyword extraction function, import `extract_keywords` from `messageanalyzer.extract_keywords`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from messageanalyzer.extract_keywords import extract_keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below extracts top keywords from the list of messages using TF-IDF. Each message's keywords are determined based on their importance relative to the entire group chat. This is made possible by specifying the parameter `method`=\"tfidf\" and `num_keywords` = 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['watched', 'series', 'latest'], ['worth', 'watching', 'yes'], ['twists', 'totally', 'season'], ['watchlist', 'okay', 'intrigued'], ['today', 'thinking', 'suggestions']]\n"
     ]
    }
   ],
   "source": [
    "keywords = extract_keywords(sample_text, method=\"tfidf\", num_keywords=3)\n",
    "\n",
    "print(keywords[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above results, we can see that the group talks a lot about watching TV series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling\n",
    "\n",
    "Another way to summarize texts is topic modeling. Topic modeling is a tool to identify and extract different topics mentioned in a text and represent these topics with a group of words or phrases originated from the text. Our topic modeling function leverages the algorithm of Non-negative Matrix Factorization to reduce the text corpus to multiple topics. This application is helpful in summarizing and identifying common themes in long texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the topic modeling function in our package, import `topic_modeling` from `messageanalyzer.topic_modeling` as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from messageanalyzer.topic_modeling import topic_modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can apply topic modeling to our sample texts. \n",
    "\n",
    "Below returns 10 topics via topic modeling, where each topic is represented by 3 words selected from the sample texts. This is made possible by specifying the parameter `n_topics` = 10 and `n_words` = 3. \n",
    "\n",
    "Note: A runtime warning might be returned but it is expected when the number of topics requested exceeds the maximum number of topics that Non-negative Matrix Factorization will extracts. It will still return as many topics as requested while throwing a warning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Topic 1': ['ii', 'quality', 'hyperx'],\n",
       " 'Topic 2': ['yes', 'tegenungan', 'breathtaking'],\n",
       " 'Topic 3': ['incredible', 'hands', 'beaches'],\n",
       " 'Topic 4': ['like', 'ai', 'fast'],\n",
       " 'Topic 5': ['insane', 'twists', 'season'],\n",
       " 'Topic 6': ['flavor', 'adding', 'sea'],\n",
       " 'Topic 7': ['worth', 'watching', 'suggestions'],\n",
       " 'Topic 8': ['little', 'sure', 'exciting'],\n",
       " 'Topic 9': ['did', 'nice', 'oh'],\n",
       " 'Topic 10': ['new', 'latest', 'episode']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_modeling(sample_text, n_topics = 10, n_words = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like using 3 representative words for each topic is not too insightful. We have topics like `Topic 5`, i.e. a topic on insane twists in a TV series season, that are easy to comprehend, but we also have topics like `Topic 9` that do not tell us anything useful. Let's try adding more words for each topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we extract 5 words from the sample texts to represent 10 topics. The `random_state` parameter is also specified to ensure reproducibility when rerunning the function. The default of `random_state` is set to `123`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lizzyhuang/miniforge3/envs/text/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:1742: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Topic 1': ['incredible', 'hands', 'beaches', 'bali', 'little'],\n",
       " 'Topic 2': ['new', 'series', 'episode', 'latest', 'hey'],\n",
       " 'Topic 3': ['insane', 'season', 'totally', 'twists', 'chip'],\n",
       " 'Topic 4': ['okay', 'watchlist', 'intrigued', 'adding', 'try'],\n",
       " 'Topic 5': ['yes', 'waterfall', 'tegenungan', 'breathtaking', 'helping'],\n",
       " 'Topic 6': ['like', 'ai', 'feel', 'fast', 'moving'],\n",
       " 'Topic 7': ['cookies', 'flavor', 'sea', 'salt', 'suggestions'],\n",
       " 'Topic 8': ['pick', 'heard', 'things', 'great', 'good'],\n",
       " 'Topic 9': ['did', 'nice', 'waterfalls', 'oh', 'wanted'],\n",
       " 'Topic 10': ['sound', 'hyperx', 'super', 'quality', 'comfortable']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_modeling(sample_text, n_topics = 10, n_words = 5, random_state = 456)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is more informative and detailed than the previous result. For instance, we can now deduce that the group talked about the incredible beaches in Bali from `Topic 1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sentiment analysis also evaluates the sentiment of one or more input messages using `TextBlob`. Our function calculates a polarity score and labels the sentiment as positive, negative, or neutral. If the sentiment is highly negative (below -0.2), it triggers an alert. The function returns a list of dictionaries with the message, sentiment score, label, and alert flag if applicable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the keyword extraction function, import `analyze_sentiment` from `messageanalyzer.analyze_sentiment`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from messageanalyzer.sentiment_analysis import analyze_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below shows how to use `analyze_sentiment` function to perform sentiment analysis with our sample_text. The \"Default\" model here utilizes the pretrained model from TextBlob. The sentiment of each text string will be evaluated through the model's polarity, and will be categorized as postive, negative and neutral by the value. In addition, we would pay more attention to those text messages that convey highly negative content, and will trigger alert if the value is smaller than the threshold -0.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALERT: Message is highly negative - Totally! The twists this season are insane.\n",
      "ALERT: Message is highly negative - Agreed. I mean, just look at how tools like ChatGPT are changing how we work.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'message': 'Hey, has anyone watched the latest episode of that new series?',\n",
       "  'score': 0.3181818181818182,\n",
       "  'label': 'positive'},\n",
       " {'message': 'Not yet! Is it worth watching?',\n",
       "  'score': 0.3,\n",
       "  'label': 'positive'},\n",
       " {'message': 'Totally! The twists this season are insane.',\n",
       "  'score': -0.5,\n",
       "  'alert': True,\n",
       "  'label': 'negative'},\n",
       " {'message': 'Okay, now I’m intrigued. Adding it to my watchlist.',\n",
       "  'score': 0.5,\n",
       "  'label': 'positive'},\n",
       " {'message': 'I’m thinking of baking cookies today. Any flavor suggestions?',\n",
       "  'score': 0.0,\n",
       "  'label': 'neutral'},\n",
       " {'message': 'Chocolate chip, always a classic!',\n",
       "  'score': 0.20833333333333331,\n",
       "  'label': 'positive'},\n",
       " {'message': 'Good choice! I’ll try adding some sea salt on top for extra flavor.',\n",
       "  'score': 0.4583333333333333,\n",
       "  'label': 'positive'},\n",
       " {'message': 'Ooh, sea salt on cookies? That sounds amazing. Let us know how it turns out.What’s the best vacation spot you’ve been to?',\n",
       "  'score': 0.8,\n",
       "  'label': 'positive'},\n",
       " {'message': 'Bali, hands down. The beaches are incredible.',\n",
       "  'score': 0.37222222222222223,\n",
       "  'label': 'positive'},\n",
       " {'message': 'Oh, I’ve always wanted to visit Bali. Did you go to any of the waterfalls there?',\n",
       "  'score': 0.0,\n",
       "  'label': 'neutral'},\n",
       " {'message': 'Yes! Tegenungan Waterfall was breathtaking.',\n",
       "  'score': 1.0,\n",
       "  'label': 'positive'},\n",
       " {'message': 'Does anyone else feel like AI is moving so fast?',\n",
       "  'score': 0.2,\n",
       "  'label': 'positive'},\n",
       " {'message': 'For sure. It’s exciting but also a little scary sometimes.',\n",
       "  'score': 0.02812500000000001,\n",
       "  'label': 'positive'},\n",
       " {'message': 'Agreed. I mean, just look at how tools like ChatGPT are changing how we work.',\n",
       "  'score': -0.3125,\n",
       "  'alert': True,\n",
       "  'label': 'negative'},\n",
       " {'message': 'True, but it’s also helping with so many tasks I used to find tedious.',\n",
       "  'score': 0.11666666666666665,\n",
       "  'label': 'positive'},\n",
       " {'message': 'I just got a new gaming headset, and it’s a game-changer!',\n",
       "  'score': 0.17045454545454544,\n",
       "  'label': 'positive'},\n",
       " {'message': 'Nice! Which one did you get?',\n",
       "  'score': 0.75,\n",
       "  'label': 'positive'},\n",
       " {'message': 'The HyperX Cloud II. The sound quality is amazing, and it’s super comfortable.',\n",
       "  'score': 0.43333333333333335,\n",
       "  'label': 'positive'},\n",
       " {'message': 'I’ve heard good things about that one. Great pick!',\n",
       "  'score': 0.85,\n",
       "  'label': 'positive'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_sentiment(sample_text, \"Default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above results shows that in our sample text, some text strings contains very negative sentiments, while some others convey very positive sentiments. Extra alerts are printed too because those message have very high negative polarity scores that are less than -0.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect Language Patterns\n",
    "\n",
    "Detecting language patterns is another great way to get a better understanding of text messages, especially when you have an international group of peers that speak in different languages. \n",
    "\n",
    "The `detect_language_patterns`function spots patterns like common n-grams (word combinations), frequently used characters, or the mix of languages in a dataset. These patterns can help you see key trends and details in the text, like often-mentioned terms, writing styles, or the overall language makeup.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the language pattern detection function, import `detect_language_patterns` from `messageanalyzer.detect_language_patterns` as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from messageanalyzer.detect_language_patterns import detect_language_patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using a different sample text below to test the function's ability to read a mix of languages. The sample covers a mix of themes, including artificial intelligence and meditation, and a mix of languages, including English, French, and Chinese."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_text = [\n",
    "    \"Artificial intelligence and machine learning are transforming industries around the globe.\",\n",
    "    \"The basketball team secured a thrilling victory in the final seconds of the game.\",\n",
    "    \"Yoga and meditation are excellent for reducing stress and improving mental health.\",\n",
    "    \"Exploring the hidden beaches of Bali is an unforgettable experience for any traveler.\",\n",
    "    \"Quantum computing is expected to revolutionize data processing and cryptography.\",\n",
    "    \"L'intelligence artificielle et l'apprentissage automatique transforment les industries du monde entier.\",\n",
    "    \"L'équipe de basket-ball a remporté une victoire passionnante dans les dernières secondes du match.\",\n",
    "    \"Le yoga et la méditation sont excellents pour réduire le stress et améliorer la santé mentale.\",\n",
    "    \"L'exploration des plages cachées de Bali est une expérience inoubliable pour tout voyageur.\",\n",
    "    \"L'informatique quantique devrait révolutionner le traitement des données et la cryptographie.\",\n",
    "    \"人工智能和机器学习正在改变全球各行各业。\",\n",
    "    \"篮球队在比赛的最后几秒钟取得了激动人心的胜利。\",\n",
    "    \"瑜伽和冥想是减压和改善心理健康的绝佳方式。\",\n",
    "    \"探索巴厘岛隐秘的海滩对任何旅行者来说都是一次难忘的经历。\",\n",
    "    \"量子计算有望彻底改变数据处理和密码学。\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example below demonstrates how to use the **`detect_language_patterns`** function to analyze the sample text.\n",
    "\n",
    "1. **Language Detection**  \n",
    "   The first part detects the language of each message in the sample text by setting the parameter `method=\"language\"`. The result is a list of detected languages, where each entry corresponds to the language of a sentence in the sample text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['en', 'en', 'en', 'en', 'en', 'fr', 'fr', 'fr', 'fr', 'fr', 'zh-cn', 'zh-cn', 'zh-cn', 'zh-cn', 'zh-cn']\n"
     ]
    }
   ],
   "source": [
    "# Detect the language of each message in the sample text\n",
    "result = detect_language_patterns(mix_text, method=\"language\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each detected language (`en` for English, `fr` for French, and `zh-cn` for Chinese) corresponds to a sentence in the sample_text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Bigram Extraction**  \n",
    "   The second part identifies the top 5 most common bigrams (two-word combinations) in the sample text by setting the parameters `method=\"ngrams\"`, `n=2`, and `top_n=5`. The output shows the bigrams along with their frequencies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('et la', 2), ('artificial intelligence', 1), ('intelligence and', 1), ('and machine', 1), ('machine learning', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Extract the top 5 most common bigrams (two-word combinations)\n",
    "result = detect_language_patterns(mix_text, method=\"ngrams\", n=2, top_n=5)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bigram `et la` appears twice in the French sentences, while other bigrams occur once in the English sentences."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:text]",
   "language": "python",
   "name": "conda-env-text-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
