{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Tutorial on Analyzing Group Chats\n",
                "\n",
                "Reading all the messages from a group chat can be a tedious task, especially when you receive over 100 text messages while you are away. `txtanalyzer` can alleviate your heavy reading load by providing an accessible gateway to Natural Language Processing (NLP) and supporting you with fast, efficient analyzing tools. This is a short tutorial on performing several Natural Language Processing (NLP) tasks on group chats using `txtanalyzer`. \n",
                "\n",
                "For this tutorial, we will introduce and guide you through four popular NLP tasks leveraging the functions in `txtanalyzer`:\n",
                "- Extract keywords\n",
                "- Extract topics\n",
                "- Sentiment analysis\n",
                "- Detect language patterns\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Import\n",
                "\n",
                "First, let's import `txtanalyzer` as below. We can check the version of `txtanalyzer` by using the attribute `.__version__`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "0.1.0\n"
                    ]
                }
            ],
            "source": [
                "import txtanalyzer\n",
                "\n",
                "print(txtanalyzer.__version__)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Below is a list of sample texts that cover a diverse range of conversations among peers. We will work on this sample texts for the majority of the tutorial."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "sample_text = [\n",
                "    \"Hey, has anyone watched the latest episode of that new series?\",\n",
                "    \"Not yet! Is it worth watching?\",\n",
                "    \"Totally! The twists this season are insane.\",\n",
                "    \"Okay, now I’m intrigued. Adding it to my watchlist.\",\n",
                "    \"I’m thinking of baking cookies today. Any flavor suggestions?\",\n",
                "    \"Chocolate chip, always a classic!\",\n",
                "    \"Good choice! I’ll try adding some sea salt on top for extra flavor.\",\n",
                "    \"Ooh, sea salt on cookies? That sounds amazing. Let us know how it turns out.\"\n",
                "    \"What’s the best vacation spot you’ve been to?\",\n",
                "    \"Bali, hands down. The beaches are incredible.\",\n",
                "    \"Oh, I’ve always wanted to visit Bali. Did you go to any of the waterfalls there?\",\n",
                "    \"Yes! Tegenungan Waterfall was breathtaking.\",\n",
                "    \"Does anyone else feel like AI is moving so fast?\",\n",
                "    \"For sure. It’s exciting but also a little scary sometimes.\",\n",
                "    \"Agreed. I mean, just look at how tools like ChatGPT are changing how we work.\",\n",
                "    \"True, but it’s also helping with so many tasks I used to find tedious.\",\n",
                "    \"I just got a new gaming headset, and it’s a game-changer!\",\n",
                "    \"Nice! Which one did you get?\",\n",
                "    \"The HyperX Cloud II. The sound quality is amazing, and it’s super comfortable.\",\n",
                "    \"I’ve heard good things about that one. Great pick!\"\n",
                "]\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Keyword Extraction\n",
                "\n",
                "Keyword extraction is a technique to identify and extract the most relevant words or phrases from a given set of text messages. This function supports keyword extraction by using the Term Frequency-Inverse Document Frequency (TF-IDF). It is helpful in summarizing text, identifying key terms, or preprocessing data for further text analysis tasks."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "To use the keyword extraction function, import `extract_keywords` from `txtanalyzer.extract_keywords`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "from txtanalyzer.extract_keywords import extract_keywords"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Below extracts top keywords from the list of messages using TF-IDF. Each message's keywords are determined based on their importance relative to the entire group chat. This is made possible by specifying the parameter `method`=\"tfidf\" and `num_keywords` = 3."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[['watched', 'series', 'latest'], ['worth', 'watching', 'yes'], ['twists', 'totally', 'season'], ['watchlist', 'okay', 'intrigued'], ['today', 'thinking', 'suggestions']]\n"
                    ]
                }
            ],
            "source": [
                "keywords = extract_keywords(sample_text, method=\"tfidf\", num_keywords=3)\n",
                "\n",
                "print(keywords[:5])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "From the above results, we can see that the group talks a lot about watching TV series."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Topic Modeling\n",
                "\n",
                "Another way to summarize texts is topic modeling. Topic modeling is a tool to identify and extract different topics mentioned in a text and represent these topics with a group of words or phrases originated from the text. Our topic modeling function leverages the algorithm of Non-negative Matrix Factorization to reduce the text corpus to multiple topics. This application is helpful in summarizing and identifying common themes in long texts."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "To use the topic modeling function in our package, import `topic_modeling` from `txtanalyzer.topic_modeling` as below."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "from txtanalyzer.topic_modeling import topic_modeling"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now we can apply topic modeling to our sample texts. \n",
                "\n",
                "Below returns 10 topics via topic modeling, where each topic is represented by 3 words selected from the sample texts. This is made possible by specifying the parameter `n_topics` = 10 and `n_words` = 3. \n",
                "\n",
                "Note: A runtime warning might be returned but it is expected when the number of topics requested exceeds the maximum number of topics that Non-negative Matrix Factorization will extracts. It will still return as many topics as requested while throwing a warning."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'Topic 1': ['ii', 'quality', 'hyperx'],\n",
                            " 'Topic 2': ['yes', 'tegenungan', 'breathtaking'],\n",
                            " 'Topic 3': ['incredible', 'hands', 'beaches'],\n",
                            " 'Topic 4': ['like', 'ai', 'fast'],\n",
                            " 'Topic 5': ['insane', 'twists', 'season'],\n",
                            " 'Topic 6': ['flavor', 'adding', 'sea'],\n",
                            " 'Topic 7': ['worth', 'watching', 'suggestions'],\n",
                            " 'Topic 8': ['little', 'sure', 'exciting'],\n",
                            " 'Topic 9': ['did', 'nice', 'oh'],\n",
                            " 'Topic 10': ['new', 'latest', 'episode']}"
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "topic_modeling(sample_text, n_topics = 10, n_words = 3)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "It seems like using 3 representative words for each topic is not too insightful. We have topics like `Topic 5`, i.e. a topic on insane twists in a TV series season, that are easy to comprehend, but we also have topics like `Topic 9` that do not tell us anything useful. Let's try adding more words for each topic."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Thus, we extract 5 words from the sample texts to represent 10 topics. The `random_state` parameter is also specified to ensure reproducibility when rerunning the function. The default of `random_state` is set to `123`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Users/adrianleung/miniforge3/envs/text/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:1742: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
                        "  warnings.warn(\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "{'Topic 1': ['incredible', 'hands', 'beaches', 'bali', 'little'],\n",
                            " 'Topic 2': ['new', 'latest', 'watched', 'episode', 'hey'],\n",
                            " 'Topic 3': ['insane', 'season', 'totally', 'twists', 'chip'],\n",
                            " 'Topic 4': ['okay', 'watchlist', 'intrigued', 'adding', 'try'],\n",
                            " 'Topic 5': ['yes', 'waterfall', 'tegenungan', 'breathtaking', 'helping'],\n",
                            " 'Topic 6': ['like', 'ai', 'feel', 'fast', 'moving'],\n",
                            " 'Topic 7': ['cookies', 'flavor', 'sea', 'salt', 'suggestions'],\n",
                            " 'Topic 8': ['pick', 'heard', 'things', 'great', 'good'],\n",
                            " 'Topic 9': ['did', 'nice', 'waterfalls', 'oh', 'wanted'],\n",
                            " 'Topic 10': ['sound', 'hyperx', 'super', 'quality', 'comfortable']}"
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "topic_modeling(sample_text, n_topics = 10, n_words = 5, random_state = 456)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This is more informative and detailed than the previous result. For instance, we can now deduce that the group talked about the incredible beaches in Bali from `Topic 1`."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Sentiment Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Detect Language Patterns\n",
                "\n",
                "Detecting language patterns is another great way to get a better understanding of text messages, especially when you have an international group of peers that speak in different languages. \n",
                "\n",
                "The `detect_language_patterns`function spots patterns like common n-grams (word combinations), frequently used characters, or the mix of languages in a dataset. These patterns can help you see key trends and details in the text, like often-mentioned terms, writing styles, or the overall language makeup.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "To use the language pattern detection function, import `detect_language_patterns` from `txtanalyzer.detect_language_patterns` as shown below."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "from txtanalyzer.detect_language_patterns import detect_language_patterns"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We are using a different sample text below to test the function's ability to read a mix of languages. The sample covers a mix of themes, including artificial intelligence and meditation, and a mix of languages, including English, French, and Chinese."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "mix_text = [\n",
                "    \"Artificial intelligence and machine learning are transforming industries around the globe.\",\n",
                "    \"The basketball team secured a thrilling victory in the final seconds of the game.\",\n",
                "    \"Yoga and meditation are excellent for reducing stress and improving mental health.\",\n",
                "    \"Exploring the hidden beaches of Bali is an unforgettable experience for any traveler.\",\n",
                "    \"Quantum computing is expected to revolutionize data processing and cryptography.\",\n",
                "    \"L'intelligence artificielle et l'apprentissage automatique transforment les industries du monde entier.\",\n",
                "    \"L'équipe de basket-ball a remporté une victoire passionnante dans les dernières secondes du match.\",\n",
                "    \"Le yoga et la méditation sont excellents pour réduire le stress et améliorer la santé mentale.\",\n",
                "    \"L'exploration des plages cachées de Bali est une expérience inoubliable pour tout voyageur.\",\n",
                "    \"L'informatique quantique devrait révolutionner le traitement des données et la cryptographie.\",\n",
                "    \"人工智能和机器学习正在改变全球各行各业。\",\n",
                "    \"篮球队在比赛的最后几秒钟取得了激动人心的胜利。\",\n",
                "    \"瑜伽和冥想是减压和改善心理健康的绝佳方式。\",\n",
                "    \"探索巴厘岛隐秘的海滩对任何旅行者来说都是一次难忘的经历。\",\n",
                "    \"量子计算有望彻底改变数据处理和密码学。\"\n",
                "]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The example below demonstrates how to use the **`detect_language_patterns`** function to analyze the sample text.\n",
                "\n",
                "1. **Language Detection**  \n",
                "   The first part detects the language of each message in the sample text by setting the parameter `method=\"language\"`. The result is a list of detected languages, where each entry corresponds to the language of a sentence in the sample text."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "['en', 'en', 'en', 'en', 'en', 'fr', 'fr', 'fr', 'fr', 'fr', 'zh-cn', 'zh-cn', 'zh-cn', 'zh-cn', 'zh-cn']\n"
                    ]
                }
            ],
            "source": [
                "# Detect the language of each message in the sample text\n",
                "result = detect_language_patterns(mix_text, method=\"language\")\n",
                "print(result)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Each detected language (`en` for English, `fr` for French, and `zh-cn` for Chinese) corresponds to a sentence in the sample_text."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "2. **Bigram Extraction**  \n",
                "   The second part identifies the top 5 most common bigrams (two-word combinations) in the sample text by setting the parameters `method=\"ngrams\"`, `n=2`, and `top_n=5`. The output shows the bigrams along with their frequencies.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[('sea salt', np.int64(2)), ('salt on', np.int64(2)), ('did you', np.int64(2)), ('and it', np.int64(2)), ('hey has', np.int64(1))]\n"
                    ]
                }
            ],
            "source": [
                "# Extract the top 5 most common bigrams (two-word combinations)\n",
                "result = detect_language_patterns(sample_text, method=\"ngrams\", n=2, top_n=5)\n",
                "print(result)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The bigram `et la` appears twice in the French sentences, while other bigrams occur once in the English sentences."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "text",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.21"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
